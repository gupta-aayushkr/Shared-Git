{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/30 15:00:31 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/30 15:00:36 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"customer-orders\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+\n",
      "|_c0| _c1|  _c2|\n",
      "+---+----+-----+\n",
      "| 44|8602|37.19|\n",
      "| 35|5368|65.89|\n",
      "|  2|3391|40.64|\n",
      "| 47|6694|14.98|\n",
      "| 29| 680|13.08|\n",
      "+---+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"customer-orders.csv\", inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|custID|itemID|amount|\n",
      "+------+------+------+\n",
      "|    44|  8602| 37.19|\n",
      "+------+------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.withColumnRenamed(\"_c0\",\"custID\") \\\n",
    "            .withColumnRenamed(\"_c1\",\"itemID\") \\\n",
    "            .withColumnRenamed(\"_c2\",\"amount\") \n",
    "df2.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|custID|             Total|\n",
      "+------+------------------+\n",
      "|    31|           4765.05|\n",
      "|    85|           5503.43|\n",
      "|    65|5140.3499999999985|\n",
      "|    53| 4945.299999999999|\n",
      "|    78| 4524.509999999999|\n",
      "|    34|            5330.8|\n",
      "|    81| 5112.709999999999|\n",
      "|    28| 5000.709999999998|\n",
      "|    76| 4904.209999999999|\n",
      "|    27| 4915.889999999999|\n",
      "|    26|            5250.4|\n",
      "|    44|4756.8899999999985|\n",
      "|    12| 4664.589999999998|\n",
      "|    91| 4642.259999999999|\n",
      "|    22| 5019.449999999999|\n",
      "|    93| 5265.750000000001|\n",
      "|    47| 4316.299999999999|\n",
      "|     1| 4958.600000000001|\n",
      "|    52| 5245.059999999999|\n",
      "|    13|           4367.62|\n",
      "+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df2.groupBy(\"custID\").sum(\"amount\").withColumnRenamed(\"sum(amount)\", \"Total\")\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|custID|  Total|\n",
      "+------+-------+\n",
      "|    31|4765.05|\n",
      "|    85|5503.43|\n",
      "|    65|5140.35|\n",
      "|    53| 4945.3|\n",
      "|    78|4524.51|\n",
      "|    34| 5330.8|\n",
      "|    81|5112.71|\n",
      "|    28|5000.71|\n",
      "|    76|4904.21|\n",
      "|    27|4915.89|\n",
      "|    26| 5250.4|\n",
      "|    44|4756.89|\n",
      "|    12|4664.59|\n",
      "|    91|4642.26|\n",
      "|    22|5019.45|\n",
      "|    93|5265.75|\n",
      "|    47| 4316.3|\n",
      "|     1| 4958.6|\n",
      "|    52|5245.06|\n",
      "|    13|4367.62|\n",
      "+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "df4 = df3.withColumn(\"Total\", round(df3[\"Total\"], 2))\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
